Learning a complex system is a challenging task. In the Turbulence field, it is rarely possible to have access to direct simulations and large datasets.
That is one of the main reasons which ask for the development of simplified models of the Navier-Stokes (NS) equations. 
We focus here on the Shell Models of turbulence, which have a tractable dimension, and they share with NS fundamental aspects from the Kolmogorov Scaling to Intermittency.
Our goal is to develop a suitable Machine Learning strategy to develop a robust model from data. We have chosen to analyse Recurrent networks.
The standard approach to the training of a Recurrent Neural Network (for instance LSTM) consists in giving the model each time the points in training data and minimising the loss between the training data and the generated ones. We have found that this approach is not able to provide a correct model.
This training approach creates a discrepancy between what the model learns and what the model has to be able to do. Indeed the model should be able to generate new points starting from an initial condition. We propose then a new training method.  
During the new training process, each time we give as input the points generated by the model itself. Then we minimise the loss between the generated points and the trainig ones.
We show through extensive statistical analysis that this method shows an important increase in performance, and we can train a model giving excellent agreement with the bare truth, even using a few training data.
